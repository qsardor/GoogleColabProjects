{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPgYLbib1V/d10FGv/bdvxJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qsardor/GoogleColabProjects/blob/main/Z_Image_Turbo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸš€ Z-Image-Turbo: The Ultimate Edition\n",
        "\n",
        "Run the powerful **Z-Image-Turbo** model completely free on Google Colab. This version is optimized to run fast, look good, and never crash.\n",
        "\n",
        "### âœ¨ What can it do?\n",
        "* **ðŸ“± Mobile Ready:** The interface automatically adjusts. Works perfectly on your phone or desktop.\n",
        "* **âš¡ FP8 Turbo Engine:** Uses a special \"compressed\" version of the model to fit into the free GPU memory without losing quality.\n",
        "* **ðŸ”‡ Silent Start:** No messy code logs or scrolling text. It just says \"Ready\" when it's ready.\n",
        "* **ðŸ”„ Infinite Life:** The cell keeps running in the background so Colab doesn't think you are \"idle\" and disconnect you.\n",
        "* **ðŸ–¼ï¸ PNG Output:** Downloads high-quality PNG images (instead of compressed WebP).\n",
        "* **ðŸŽ¨ Manual Control:** Full control over resolution (width/height), steps, and guidance scale.\n",
        "\n",
        "### ðŸ›‘ Limits (Real Talk)\n",
        "* **â³ Speed:** It takes about **20-30 seconds** to generate an image. (We are using a free Tesla T4 GPU from 2018, so be patient!)\n",
        "* **âš ï¸ Resolution:** Stick to **1024x1024** or **1280x720**. If you try to generate massive 4K images, the free GPU will run out of memory and crash.\n",
        "* **ðŸ”Œ 90-Minute Rule:** Google Colab Free usually kicks you off after 90 minutes or if you close the tab. Keep the tab open!\n",
        "\n",
        "### ðŸ› ï¸ How to use\n",
        "1.  Click the **Play Button** (â–¶) on the cell below.\n",
        "2.  Wait for the **\"SERVER RUNNING\"** message.\n",
        "3.  Click the **Public Link** (looks like `https://xxxx.gradio.live`) to open the app.\n",
        "\n",
        "---\n",
        "### ðŸ‘¨â€ðŸ’» Credits\n",
        "* **Creator:** Q.SARDOR\n",
        "* **GitHub:** [qsardor/GoogleColabProjects](https://github.com/qsardor/GoogleColabProjects/)\n",
        "* **Telegram:** [@qsardorblog](https://t.me/qsardorblog)"
      ],
      "metadata": {
        "id": "0B4DLdhO-Tov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ðŸš€ Z-Image-Turbo\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import warnings\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# --- 0. CONFIGURATION ---\n",
        "LOG_FILE = \"/content/install_log.txt\"\n",
        "\n",
        "def print_banner(text):\n",
        "    print(f\"\\033[1;36m>> {text}\\033[0m\")\n",
        "\n",
        "def print_success(text):\n",
        "    print(f\"\\033[1;32m[âœ”] {text}\\033[0m\")\n",
        "\n",
        "def fake_progress_bar(label, duration=2):\n",
        "    width = 25\n",
        "    print(f\"{label} [\", end=\"\", flush=True)\n",
        "    for i in range(width + 1):\n",
        "        time.sleep(duration / width)\n",
        "        progress = \"â–ˆ\" * i + \"â–‘\" * (width - i)\n",
        "        print(f\"\\r\\033[1;33m{label}\\033[0m [\\033[1;36m{progress}\\033[0m] {int(i/width*100)}%\", end=\"\", flush=True)\n",
        "    print()\n",
        "\n",
        "def log_command(command, description):\n",
        "    !echo \"--- {description} ---\" >> {LOG_FILE}\n",
        "    !{command} >> {LOG_FILE} 2>&1\n",
        "\n",
        "# --- 1. CLEAN INSTALLATION ---\n",
        "clear_output()\n",
        "!echo \"Z-Image Log\" > {LOG_FILE}\n",
        "\n",
        "print(\"\\033[1;35mâš¡ Z-IMAGE SYSTEM BOOT âš¡\\033[0m\")\n",
        "print(\"\\033[1;30m------------------------\\033[0m\")\n",
        "\n",
        "print_banner(\"System Check & Install...\")\n",
        "fake_progress_bar(\"Installing Core\", duration=3)\n",
        "\n",
        "os.chdir(\"/content\")\n",
        "# This hides warnings in the notebook cell itself\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "if not os.path.exists(\"ComfyUI\"):\n",
        "    log_command(\"git clone https://github.com/comfyanonymous/ComfyUI\", \"Cloning Repo\")\n",
        "    os.chdir(\"ComfyUI\")\n",
        "    log_command(\"pip install -r requirements.txt\", \"Installing Requirements\")\n",
        "    log_command(\"pip install gradio\", \"Installing Gradio\")\n",
        "    log_command(\"apt -y install aria2\", \"Installing Aria2\")\n",
        "\n",
        "os.chdir(\"/content/ComfyUI\")\n",
        "print_success(\"Core Installed\")\n",
        "\n",
        "# --- 2. DOWNLOAD MODELS ---\n",
        "print_banner(\"Acquiring Neural Weights...\")\n",
        "fake_progress_bar(\"Downloading (FP8)\", duration=4)\n",
        "\n",
        "log_command(\"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/T5B/Z-Image-Turbo-FP8/resolve/main/z-image-turbo-fp8-e4m3fn.safetensors -d models/diffusion_models -o z-image-turbo-fp8-e4m3fn.safetensors\", \"Downloading UNET\")\n",
        "log_command(\"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/text_encoders/qwen_3_4b.safetensors -d models/clip -o qwen_3_4b.safetensors\", \"Downloading CLIP\")\n",
        "log_command(\"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/vae/ae.safetensors -d models/vae -o ae.safetensors\", \"Downloading VAE\")\n",
        "\n",
        "print_success(\"Weights Downloaded\")\n",
        "time.sleep(1)\n",
        "\n",
        "# --- 3. THE APP LOGIC ---\n",
        "app_code = \"\"\"\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "from nodes import NODE_CLASS_MAPPINGS\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "# --- AGGRESSIVE WARNING SUPPRESSION ---\n",
        "# This kills the DeprecationWarnings from showing in the terminal\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "def log_action(text):\n",
        "    print(f\"\\\\033[1;36m[ACTION]\\\\033[0m {text}\")\n",
        "\n",
        "def log_done(text):\n",
        "    print(f\"\\\\033[1;32m[DONE]\\\\033[0m {text}\")\n",
        "\n",
        "print(\"\\\\n\\\\033[1;35m>> INITIALIZING ENGINE...\\\\033[0m\")\n",
        "\n",
        "sys.path.append(os.getcwd())\n",
        "\n",
        "with torch.inference_mode():\n",
        "    UNETLoader = NODE_CLASS_MAPPINGS[\"UNETLoader\"]()\n",
        "    CLIPLoader = NODE_CLASS_MAPPINGS[\"CLIPLoader\"]()\n",
        "    VAELoader = NODE_CLASS_MAPPINGS[\"VAELoader\"]()\n",
        "    CLIPTextEncode = NODE_CLASS_MAPPINGS[\"CLIPTextEncode\"]()\n",
        "    KSampler = NODE_CLASS_MAPPINGS[\"KSampler\"]()\n",
        "    VAEDecode = NODE_CLASS_MAPPINGS[\"VAEDecode\"]()\n",
        "    EmptyLatentImage = NODE_CLASS_MAPPINGS[\"EmptyLatentImage\"]()\n",
        "\n",
        "    print(\">> Loading UNET (FP8)...\")\n",
        "    unet = UNETLoader.load_unet(\"z-image-turbo-fp8-e4m3fn.safetensors\", \"fp8_e4m3fn_fast\")[0]\n",
        "    print(\">> Loading CLIP (Qwen)...\")\n",
        "    clip = CLIPLoader.load_clip(\"qwen_3_4b.safetensors\", type=\"lumina2\")[0]\n",
        "    print(\">> Loading VAE...\")\n",
        "    vae = VAELoader.load_vae(\"ae.safetensors\")[0]\n",
        "\n",
        "log_done(\"Engine Loaded & Ready\")\n",
        "\n",
        "@torch.inference_mode()\n",
        "def generate(prompt, negative, width, height, seed, steps, cfg):\n",
        "    width, height = int(width), int(height)\n",
        "    if seed == 0: seed = random.randint(0, 2**63)\n",
        "    else: seed = int(seed)\n",
        "\n",
        "    log_action(f\"Generating: {prompt[:40]}...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    pos = CLIPTextEncode.encode(clip, prompt)[0]\n",
        "    neg = CLIPTextEncode.encode(clip, negative)[0]\n",
        "    latent = EmptyLatentImage.generate(width, height, batch_size=1)[0]\n",
        "\n",
        "    samples = KSampler.sample(unet, seed, steps, cfg, \"euler\", \"simple\", pos, neg, latent, denoise=1.0)[0]\n",
        "    decoded = VAEDecode.decode(vae, samples)[0].detach()\n",
        "\n",
        "    img = Image.fromarray(np.array(decoded * 255, dtype=np.uint8)[0])\n",
        "\n",
        "    duration = round(time.time() - start_time, 2)\n",
        "    log_done(f\"Finished in {duration}s\")\n",
        "\n",
        "    return img, str(seed)\n",
        "\n",
        "# --- UNIFIED UI ---\n",
        "css = \".container { max-width: 600px; margin: auto; }\"\n",
        "\n",
        "# We moved 'theme' and 'css' inside the launch() parameters where possible\n",
        "# or relied on the filterwarnings above to hide the complaint.\n",
        "with gr.Blocks(title=\"Z-Image Turbo\", css=css, theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"### âš¡ Z-Image Turbo\")\n",
        "\n",
        "    with gr.Column(elem_classes=[\"container\"]):\n",
        "        prompt = gr.Textbox(label=\"Prompt\", lines=3, placeholder=\"Describe your image...\")\n",
        "\n",
        "        with gr.Accordion(\"âš™ï¸ Settings\", open=False):\n",
        "            neg = gr.Textbox(label=\"Negative\", value=\"low quality, blurry, pixelated\")\n",
        "            width = gr.Slider(512, 2048, step=64, value=1024, label=\"Width\")\n",
        "            height = gr.Slider(512, 2048, step=64, value=1024, label=\"Height\")\n",
        "            steps = gr.Slider(4, 20, value=8, step=1, label=\"Steps\")\n",
        "            cfg = gr.Slider(1.0, 3.0, value=1.0, step=0.1, label=\"CFG\")\n",
        "            seed = gr.Number(value=0, label=\"Seed\")\n",
        "\n",
        "        btn = gr.Button(\"ðŸŽ¨ GENERATE\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "        out_img = gr.Image(label=\"Result\", format=\"png\")\n",
        "        out_seed = gr.Textbox(label=\"Seed Used\", show_copy_button=True)\n",
        "\n",
        "    btn.click(generate, [prompt, neg, width, height, seed, steps, cfg], [out_img, out_seed])\n",
        "\n",
        "print(\"\\\\n\\\\033[1;33m>> SERVER RUNNING. OPEN LINK BELOW <<\\\\033[0m\")\n",
        "\n",
        "# Launch with allowed_paths to prevent errors if saving elsewhere\n",
        "demo.launch(share=True, inline=False, debug=False)\n",
        "\"\"\"\n",
        "\n",
        "with open(\"run_z_image.py\", \"w\") as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "# --- 4. EXECUTE ---\n",
        "!python run_z_image.py"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hVJjuqwGLNAB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}