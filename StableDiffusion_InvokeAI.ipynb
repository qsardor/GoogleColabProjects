{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qsardor/GoogleColabProjects/blob/main/StableDiffusion_InvokeAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anqY-GmKTL8V"
      },
      "source": [
        "# **StableDiffusion InvokeAI**\n",
        "![pp.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAtUlEQVQ4jWNgYGBYCcSrgLibARNwAnEUEE8G4gVAXAvEOuiK/gHxfyC+gCbuAMSPoXLIGKR+NhBz4DPACoh/YNGMjDcAMSM2A5iB+DoBzTAcgc0AByI1g/BebAYUkWDAe2wGlJFgwBdsBviTYMBpbAZwAfFLIg0owGYACEQRofk8AzQt4EpI2UD8C4fmk0AsBVOIywAQUGaAJPEjQHwJiNcBcTQDJK3AAT4DiAIDbwC+7EwQAADZX5HHysvpxQAAAABJRU5ErkJggg==) [Other Notebooks](https://github.com/qsardor/GoogleColabProjects/)\n",
        "\n",
        "_You don't need additional Google Drive storage because uploaded models are not stored on your Google Drive. After the session ends, all data will be deleted._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ5qVdNPFqYJ"
      },
      "outputs": [],
      "source": [
        "#@markdown # **STEP 1**\n",
        "#@markdown ## Requirements\n",
        "#@markdown It might finished with error but is not the error, just execute the next cell\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/rocketpal/InvokeAI\n",
        "!pip install -q dependency_injector diffusers einops eventlet facexlib flask_cors flask_socketio flaskwebgui getpass_asterisk huggingface-hub\n",
        "!pip install -q kornia omegaconf pudb pyreadline3 pytorch-lightning realesrgan streamlit taming-transformers-rom1504 test-tube torch-fidelity\n",
        "!pip install -q torchmetrics transformers picklescan\n",
        "!pip install -q pillow xformers==0.0.22 triton==2.0.0 -U\n",
        "clear_output()\n",
        "\n",
        "!pip install -q git+https://github.com/invoke-ai/GFPGAN@basicsr-1.4.2#egg=gfpgan\n",
        "!pip install -q git+https://github.com/openai/CLIP.git@main#egg=clip\n",
        "!pip install -q git+https://github.com/Birch-san/k-diffusion.git@mps#egg=k-diffusion\n",
        "!pip install -q git+https://github.com/invoke-ai/clipseg.git@relaxed-python-requirement#egg=clipseg\n",
        "!pip install -q git+https://github.com/invoke-ai/PyPatchMatch@0.1.4#egg=pypatchmatch\n",
        "%cd /content/InvokeAI/\n",
        "!pip install -q -e .\n",
        "clear_output()\n",
        "\n",
        "\n",
        "!wget https://raw.githubusercontent.com/rocketpal/InvokeAI-colab/main/INITIAL_MODELS.yaml -O /content/InvokeAI/invokeai/configs/INITIAL_MODELS.yaml\n",
        "clear_output()\n",
        "\n",
        "print('\u001b[1;32mDone!')\n",
        "\n",
        "!pip install python-socketio==5.9.0\n",
        "clear_output()\n",
        "\n",
        "#exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBZ0AbI-U_zk"
      },
      "outputs": [],
      "source": [
        "#@markdown # **STEP 2**\n",
        "#@markdown ## Downloading models _(checkpoints, LoRAs, ControlNets, etc.)_\n",
        "#@markdown To configure the downloading of models, edit this file:\n",
        "#@markdown _/content/InvokeAI/invokeai/configs/INITIAL_MODELS.yaml_\n",
        "\n",
        "#@markdown P.S. It's fully explained in the tutorial.\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content/InvokeAI/\n",
        "!python /content/InvokeAI/scripts/invokeai-model-install.py --root_dir /content/db --yes\n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mDone! All models downloaded successfully ðŸ™ƒ')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuFwU5t8POIS"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Load Model (option2)\n",
        "model_link = \"https://civitai.com/api/download/models/128713?type=Model&format=SafeTensor&size=pruned&fp=fp16\" # @param {type:\"string\"}\n",
        "\n",
        "!wget -O /content/db/models/sd-1/main/model.safetensors \"{model_link}\"\n",
        "\n",
        "clear_output()\n",
        "print(' [1;32m Model just loaded! ðŸš€')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BWoTrZLRP5zh"
      },
      "outputs": [],
      "source": [
        "#@markdown # **STEP 3**\n",
        "#@markdown ## Run StableDiffusion InvokeAI\n",
        "\n",
        "import os\n",
        "import shlex\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from typing import Union\n",
        "clear_output()\n",
        "\n",
        "\n",
        "id_rsa_file = \"/content/InvokeAI/id_rsa\"\n",
        "id_rsa_pub_file = \"/content/InvokeAI/id_rsa.pub\"\n",
        "if os.path.exists(id_rsa_file):\n",
        "    os.remove(id_rsa_file)\n",
        "if os.path.exists(id_rsa_pub_file):\n",
        "    os.remove(id_rsa_pub_file)\n",
        "clear_output()\n",
        "\n",
        "def gen_key(path: Union[str, Path]) -> None:\n",
        "    path = Path(path)\n",
        "    arg_string = f'ssh-keygen -t rsa -b 4096 -N \"\" -q -f {path.as_posix()}'\n",
        "    args = shlex.split(arg_string)\n",
        "    subprocess.run(args, check=True)\n",
        "    path.chmod(0o600)\n",
        "\n",
        "ssh_name = \"id_rsa\"\n",
        "ssh_path = Path(os.path.dirname(os.getcwd())) / ssh_name\n",
        "gen_key(ssh_path)\n",
        "clear_output()\n",
        "\n",
        "import threading\n",
        "def tunnel():\n",
        "  !ssh -R 80:127.0.0.1:9090 -o StrictHostKeyChecking=no -i /content/id_rsa remote.moe\n",
        "threading.Thread(target=tunnel, daemon=True).start()\n",
        "\n",
        "%cd /content/InvokeAI/\n",
        "!python /content/InvokeAI/scripts/invokeai-web.py --root /content/db"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}