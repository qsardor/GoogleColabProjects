{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qsardor/GoogleColabProjects/blob/main/DeepFake_FaceFusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaqO7feu9sAw",
        "outputId": "4751c22b-8e10-4467-8e60-66a2035d5d3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installed!\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "import codecs\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device=\"cuda\"\n",
        "  !apt-get install nvidia-cuda-toolkit\n",
        "  print(\"Using GPU\")\n",
        "else:\n",
        "  device=\"cpu\"\n",
        "  print(\"Using CPU\")\n",
        "\n",
        "giturl = codecs.decode('uggcf://tvguho.pbz/Mnpulfnhef/snprshfvba.tvg','rot_13')\n",
        "gitdir = codecs.decode('snprshfvba','rot_13')\n",
        "!git clone {giturl}\n",
        "%cd /content/{gitdir}\n",
        "!python install.py --onnxruntime cuda-11.8 --skip-conda\n",
        "\n",
        "clear_output()\n",
        "print(\"Installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import codecs\n",
        "gitdir = codecs.decode('snprshfvba','rot_13')\n",
        "%cd /content/{gitdir}\n",
        "\n",
        "if device==\"cuda\":\n",
        "  !python run.py --execution-providers cpu cuda\n",
        "else:\n",
        "  !python run.py --execution-providers cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "996UKUjT-BEu",
        "outputId": "e5e76c97-707b-45ac-ad8d-05dfaa39f1ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/facefusion\n",
            "Downloading: 100% 22.5M/22.5M [00:00<00:00, 46.0MB/s]\n",
            "Downloading: 100% 93.4M/93.4M [00:00<00:00, 126MB/s]\n",
            "Downloading: 100% 922k/922k [00:00<00:00, 2.27MB/s]\n",
            "Downloading: 100% 1.26M/1.26M [00:00<00:00, 2.94MB/s]\n",
            "Downloading: 100% 12.1M/12.1M [00:00<00:00, 24.8MB/s]\n",
            "Downloading: 100% 166M/166M [00:01<00:00, 137MB/s]\n",
            "Downloading: 100% 67.1M/67.1M [00:00<00:00, 85.9MB/s]\n",
            "Downloading: 100% 50.7M/50.7M [00:00<00:00, 77.7MB/s]\n",
            "Downloading: 100% 63.7M/63.7M [00:00<00:00, 77.5MB/s]\n",
            "Downloading: 100% 265M/265M [00:01<00:00, 158MB/s]\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://2b5ebfe4a2bca3731b.gradio.live\n",
            "Killing tunnel 127.0.0.1:7860 <> https://2b5ebfe4a2bca3731b.gradio.live\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}