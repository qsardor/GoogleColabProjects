{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOngJIY4pSGJtGlum6OwAvd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qsardor/GoogleColabProjects/blob/main/Pain_Undo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3g9tIPvbCpBY",
        "outputId": "d3e9f1d7-0ecb-43be-c36b-8b1663fd3d97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 0: Checking Resources ---\n",
            "Sun Apr  6 16:10:30 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "System RAM:\n",
            "               total        used        free      shared  buff/cache   available\n",
            "Mem:            12Gi       649Mi       7.8Gi       1.0Mi       4.3Gi        11Gi\n",
            "Swap:             0B          0B          0B\n",
            "\n",
            "==============================\n",
            "\n",
            "--- Step 1: Cloning Repository ---\n",
            "Cloning into 'Paints-UNDO'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 47 (delta 14), reused 6 (delta 6), pack-reused 13 (from 1)\u001b[K\n",
            "Receiving objects: 100% (47/47), 2.11 MiB | 4.62 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n",
            "/content/Paints-UNDO\n",
            "Changed directory to: /content/Paints-UNDO\n",
            "\n",
            "==============================\n",
            "\n",
            "--- Step 2: Installing Dependencies ---\n",
            "Creating temporary requirements file excluding diffusers, gradio, transformers...\n",
            "Installing base requirements (including peft, which will pull its transformers)...\n",
            "Collecting bitsandbytes==0.43.1 (from -r temp_requirements.txt (line 1))\n",
            "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting accelerate==0.30.1 (from -r temp_requirements.txt (line 2))\n",
            "  Downloading accelerate-0.30.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting protobuf==3.20 (from -r temp_requirements.txt (line 3))\n",
            "  Downloading protobuf-3.20.0-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r temp_requirements.txt (line 4)) (4.11.0.86)\n",
            "Collecting tensorboardX (from -r temp_requirements.txt (line 5))\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from -r temp_requirements.txt (line 6)) (0.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from -r temp_requirements.txt (line 7)) (11.1.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r temp_requirements.txt (line 8)) (0.8.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r temp_requirements.txt (line 9)) (2.6.0+cu124)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (from -r temp_requirements.txt (line 10)) (0.14.0)\n",
            "Collecting xformers (from -r temp_requirements.txt (line 11))\n",
            "  Downloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting onnxruntime (from -r temp_requirements.txt (line 12))\n",
            "  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting av (from -r temp_requirements.txt (line 13))\n",
            "  Downloading av-14.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r temp_requirements.txt (line 14)) (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bitsandbytes==0.43.1->-r temp_requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1->-r temp_requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1->-r temp_requirements.txt (line 2)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1->-r temp_requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from accelerate==0.30.1->-r temp_requirements.txt (line 2)) (0.30.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r temp_requirements.txt (line 9)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r temp_requirements.txt (line 9)) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r temp_requirements.txt (line 9)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r temp_requirements.txt (line 9)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r temp_requirements.txt (line 9)) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r temp_requirements.txt (line 9))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r temp_requirements.txt (line 9))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r temp_requirements.txt (line 9))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r temp_requirements.txt (line 9))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r temp_requirements.txt (line 9))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r temp_requirements.txt (line 9))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r temp_requirements.txt (line 9))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r temp_requirements.txt (line 9))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r temp_requirements.txt (line 9))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r temp_requirements.txt (line 9)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r temp_requirements.txt (line 9)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r temp_requirements.txt (line 9)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r temp_requirements.txt (line 9))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r temp_requirements.txt (line 9)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r temp_requirements.txt (line 9)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r temp_requirements.txt (line 9)) (1.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft->-r temp_requirements.txt (line 10)) (4.50.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft->-r temp_requirements.txt (line 10)) (4.67.1)\n",
            "Collecting coloredlogs (from onnxruntime->-r temp_requirements.txt (line 12))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime->-r temp_requirements.txt (line 12)) (25.2.10)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.30.1->-r temp_requirements.txt (line 2)) (2.32.3)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->-r temp_requirements.txt (line 12))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r temp_requirements.txt (line 9)) (3.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft->-r temp_requirements.txt (line 10)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft->-r temp_requirements.txt (line 10)) (0.21.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.30.1->-r temp_requirements.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.30.1->-r temp_requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.30.1->-r temp_requirements.txt (line 2)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.30.1->-r temp_requirements.txt (line 2)) (2025.1.31)\n",
            "Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m155.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m287.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.0-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m237.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m189.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m180.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m204.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m241.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m284.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m273.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m220.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m239.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m220.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m223.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m290.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl (43.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m232.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m280.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-14.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m278.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m271.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m255.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, humanfriendly, av, tensorboardX, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, onnxruntime, nvidia-cusolver-cu12, xformers, bitsandbytes, accelerate\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.5.2\n",
            "    Uninstalling accelerate-1.5.2:\n",
            "      Successfully uninstalled accelerate-1.5.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-cloud-translate 3.20.2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-iam 2.18.3 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-aiplatform 1.87.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.30.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.0 which is incompatible.\n",
            "googleapis-common-protos 1.69.2 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-datastore 2.20.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.18.2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-spanner 3.53.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "grpc-google-iam-v1 0.14.2 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-api-core 2.24.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-firestore 2.20.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigtable 2.30.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-functions 1.20.2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-language 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-dataproc 5.18.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-pubsub 2.29.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-resource-manager 1.14.2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.30.1 av-14.3.0 bitsandbytes-0.43.1 coloredlogs-15.0.1 humanfriendly-10.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnxruntime-1.21.0 protobuf-3.20.0 tensorboardX-2.6.2.2 xformers-0.0.29.post3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "2d43512cbcf14efa8256c4bfac1b7b63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Installing specific diffusers version (0.29.0)...\n",
            "Collecting diffusers==0.29.0\n",
            "  Downloading diffusers-0.29.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.29.0) (8.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.29.0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.29.0) (0.30.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers==0.29.0) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.29.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.29.0) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.29.0) (0.5.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.29.0) (11.1.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.29.0) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.29.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.29.0) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.29.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.29.0) (4.13.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers==0.29.0) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.29.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.29.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.29.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.29.0) (2025.1.31)\n",
            "Downloading diffusers-0.29.0-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: diffusers\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.32.2\n",
            "    Uninstalling diffusers-0.32.2:\n",
            "      Successfully uninstalled diffusers-0.32.2\n",
            "Successfully installed diffusers-0.29.0\n",
            "\n",
            "Upgrading Gradio and Client...\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.23.3-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gradio-client\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.1)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.23.3-py3-none-any.whl (46.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 MB\u001b[0m \u001b[31m248.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m374.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m314.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m282.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m272.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m217.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.23.3 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.4 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0\n",
            "\n",
            "Force installing NumPy < 2.0 (numpy==1.26.4) for compatibility...\n",
            "Collecting numpy<2.0\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m299.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n",
            "--- Dependencies Installation Complete ---\n",
            "\n",
            "--- Verifying Key Package Versions ---\n",
            "Name: gradio\n",
            "Version: 5.23.3\n",
            "Name: transformers\n",
            "Version: 4.50.3\n",
            "Name: huggingface-hub\n",
            "Version: 0.30.1\n",
            "Name: diffusers\n",
            "Version: 0.29.0\n",
            "Name: peft\n",
            "Version: 0.14.0\n",
            "Name: numpy\n",
            "Version: 1.26.4\n",
            "Name: lapack-lite\n",
            "Name: tempita\n",
            "Name: dragon4\n",
            "Name: libdivide\n",
            "Name: Meson\n",
            "Name: spin\n",
            "Name: OpenBLAS\n",
            "Name: LAPACK\n",
            "Name: GCC runtime library\n",
            "Name: libquadmath\n",
            "\n",
            "==============================\n",
            "\n",
            "--- Step 3: Patching installed transformers library ---\n",
            "Found transformers file at: /usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py\n",
            "  Original Line 1100: hidden_states = self.embeddings(pixel_values, interpolate_pos_encoding=interpolate_pos_encoding)\n",
            "  Patched Line 1100:  hidden_states = self.embeddings(pixel_values)\n",
            "Writing patched file...\n",
            "--- Successfully patched modeling_clip.py ---\n",
            "\n",
            "==============================\n",
            "\n",
            "--- Step 4: Ensuring share=True in Gradio App ---\n",
            "Added share=True to launch() call.\n",
            "--- Checking modification (last few lines of gradio_app.py) ---\n",
            "        inputs=[input_fg, seed, i2v_seed],\n",
            "        examples_per_page=1024\n",
            "    )\n",
            "\n",
            "block.queue().launch(server_name='0.0.0.0', share=True)\n",
            "\n",
            "\n",
            "\n",
            "==============================\n",
            "\n",
            "--- Step 5: Launching Gradio App on Colab Free Tier ---\n",
            "Watch System RAM usage closely in 'Runtime -> View resources'.\n",
            "EXPECTED TO FAIL due to RAM limits during model loading.\n",
            "2025-04-06 16:12:39.312251: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743955959.555429    1215 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743955959.617189    1215 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-06 16:12:40.134142: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.\n",
            "  deprecate(\"Transformer2DModelOutput\", \"1.0.0\", deprecation_message)\n",
            "tokenizer_config.json: 100% 704/704 [00:00<00:00, 3.79MB/s]\n",
            "vocab.json: 100% 1.06M/1.06M [00:00<00:00, 17.8MB/s]\n",
            "merges.txt: 100% 525k/525k [00:00<00:00, 12.0MB/s]\n",
            "special_tokens_map.json: 100% 585/585 [00:00<00:00, 3.58MB/s]\n",
            "config.json: 100% 618/618 [00:00<00:00, 4.44MB/s]\n",
            "model.safetensors: 100% 232M/232M [00:00<00:00, 279MB/s]\n",
            "config.json: 100% 787/787 [00:00<00:00, 5.38MB/s]\n",
            "diffusion_pytorch_model.safetensors: 100% 167M/167M [00:00<00:00, 283MB/s]\n",
            "config.json: 100% 1.83k/1.83k [00:00<00:00, 13.3MB/s]\n",
            "diffusion_pytorch_model.safetensors: 100% 1.72G/1.72G [00:08<00:00, 196MB/s]\n",
            "Fetching 19 files:   0% 0/19 [00:00<?, ?it/s]\n",
            "model.safetensors:   0% 0.00/1.26G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model.safetensors:   0% 0.00/97.6M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "config.json: 100% 198/198 [00:00<00:00, 1.35MB/s]\n",
            "\n",
            "\n",
            "\n",
            "README.md: 100% 76.0/76.0 [00:00<00:00, 508kB/s]\n",
            "\n",
            "\n",
            "\n",
            ".gitattributes: 100% 1.52k/1.52k [00:00<00:00, 14.9MB/s]\n",
            "Fetching 19 files:   5% 1/19 [00:00<00:05,  3.21it/s]\n",
            "model.safetensors:   1% 10.5M/1.26G [00:00<00:20, 62.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "config.json: 100% 696/696 [00:00<00:00, 5.07MB/s]\n",
            "\n",
            "model.safetensors:   2% 21.0M/1.26G [00:00<00:15, 80.8MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  11% 10.5M/97.6M [00:00<00:01, 58.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   0% 0.00/681M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   3% 41.9M/1.26G [00:00<00:09, 125MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "special_tokens_map.json: 100% 574/574 [00:00<00:00, 3.31MB/s]\n",
            "\n",
            "\n",
            "model.safetensors:  21% 21.0M/97.6M [00:00<00:01, 74.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   2% 10.5M/681M [00:00<00:08, 79.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_config.json: 100% 855/855 [00:00<00:00, 6.07MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "merges.txt: 100% 525k/525k [00:00<00:00, 26.1MB/s]\n",
            "\n",
            "\n",
            "model.safetensors:  32% 31.5M/97.6M [00:00<00:00, 78.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   3% 21.0M/681M [00:00<00:08, 80.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   5% 62.9M/1.26G [00:00<00:10, 110MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   5% 31.5M/681M [00:00<00:07, 85.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "vocab.json:   0% 0.00/1.06M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  43% 41.9M/97.6M [00:00<00:00, 70.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "config.json: 100% 798/798 [00:00<00:00, 4.96MB/s]\n",
            "vocab.json: 100% 1.06M/1.06M [00:00<00:00, 9.78MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "config.json: 100% 725/725 [00:00<00:00, 3.48MB/s]\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   6% 41.9M/681M [00:00<00:08, 75.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "README.md: 100% 320/320 [00:00<00:00, 1.72MB/s]\n",
            "\n",
            "model.safetensors:   7% 83.9M/1.26G [00:00<00:12, 97.2MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  54% 52.4M/97.6M [00:00<00:00, 67.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   0% 0.00/2.88G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   8% 52.4M/681M [00:00<00:08, 77.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  64% 62.9M/97.6M [00:00<00:00, 69.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   0% 0.00/200M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "config.json: 100% 224/224 [00:00<00:00, 884kB/s]\n",
            "\n",
            "model.safetensors:   8% 105M/1.26G [00:01<00:13, 86.4MB/s] \u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   9% 62.9M/681M [00:00<00:08, 71.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  75% 73.4M/97.6M [00:01<00:00, 68.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   5% 10.5M/200M [00:00<00:03, 50.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   0% 10.5M/2.88G [00:00<01:29, 31.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  86% 83.9M/97.6M [00:01<00:00, 64.6MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:   9% 115M/1.26G [00:01<00:15, 76.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  11% 73.4M/681M [00:01<00:09, 63.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   1% 21.0M/2.88G [00:00<01:03, 44.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  10% 21.0M/200M [00:00<00:03, 45.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  12% 83.9M/681M [00:01<00:09, 60.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  97% 94.4M/97.6M [00:01<00:00, 58.0MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  10% 126M/1.26G [00:01<00:17, 65.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   1% 31.5M/2.88G [00:00<00:57, 49.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  16% 31.5M/200M [00:00<00:03, 51.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors: 100% 97.6M/97.6M [00:01<00:00, 59.9MB/s]\n",
            "\n",
            "model.safetensors:  11% 136M/1.26G [00:01<00:17, 63.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  21% 41.9M/200M [00:00<00:02, 58.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   1% 41.9M/2.88G [00:00<00:50, 55.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  15% 105M/681M [00:01<00:08, 64.5MB/s] \u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  12% 147M/1.26G [00:01<00:16, 68.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  26% 52.4M/200M [00:03<00:13, 11.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   2% 52.4M/2.88G [00:05<07:22, 6.39MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  17% 115M/681M [00:05<01:19, 7.14MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  12% 157M/1.26G [00:06<02:18, 8.01MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  31% 62.9M/200M [00:05<00:18, 7.58MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   2% 62.9M/2.88G [00:05<05:19, 8.80MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   3% 73.4M/2.88G [00:05<03:44, 12.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  14% 178M/1.26G [00:06<01:20, 13.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  20% 136M/681M [00:06<00:43, 12.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  42% 83.9M/200M [00:05<00:08, 13.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   3% 83.9M/2.88G [00:05<02:44, 16.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  22% 147M/681M [00:06<00:33, 16.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  15% 189M/1.26G [00:06<01:04, 16.8MB/s]\u001b[A\n",
            "model.safetensors:  16% 199M/1.26G [00:06<00:50, 21.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  52% 105M/200M [00:05<00:04, 21.7MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   4% 105M/2.88G [00:05<01:35, 29.2MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  25% 168M/681M [00:06<00:20, 25.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  17% 210M/1.26G [00:06<00:39, 26.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   4% 115M/2.88G [00:05<01:20, 34.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  58% 115M/200M [00:05<00:03, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  26% 178M/681M [00:06<00:17, 28.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  17% 220M/1.26G [00:07<00:33, 31.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  63% 126M/200M [00:06<00:02, 30.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   4% 126M/2.88G [00:06<01:10, 38.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  28% 189M/681M [00:08<00:28, 17.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  68% 136M/200M [00:07<00:03, 17.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   5% 136M/2.88G [00:07<02:25, 18.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  18% 231M/1.26G [00:08<01:02, 16.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  73% 147M/200M [00:07<00:02, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   5% 147M/2.88G [00:07<01:51, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  29% 199M/681M [00:08<00:22, 21.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  19% 241M/1.26G [00:08<00:48, 20.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  31% 210M/681M [00:08<00:17, 26.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   5% 157M/2.88G [00:07<01:32, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  84% 168M/200M [00:07<00:00, 33.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  20% 252M/1.26G [00:08<00:37, 26.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  34% 231M/681M [00:08<00:11, 40.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   6% 178M/2.88G [00:07<01:02, 43.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  22% 273M/1.26G [00:08<00:25, 38.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  35% 241M/681M [00:08<00:10, 43.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  94% 189M/200M [00:07<00:00, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   7% 189M/2.88G [00:08<00:55, 48.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  37% 252M/681M [00:08<00:08, 50.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors: 100% 199M/200M [00:08<00:00, 47.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  22% 283M/1.26G [00:09<00:22, 42.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors: 100% 200M/200M [00:08<00:00, 24.6MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   7% 210M/2.88G [00:08<01:25, 31.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  40% 273M/681M [00:09<00:10, 37.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  24% 304M/1.26G [00:09<00:28, 33.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   8% 220M/2.88G [00:08<01:08, 38.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  42% 283M/681M [00:09<00:09, 43.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  25% 315M/1.26G [00:10<00:24, 38.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  43% 294M/681M [00:09<00:07, 48.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   8% 241M/2.88G [00:09<00:48, 54.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  45% 304M/681M [00:09<00:06, 54.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  26% 325M/1.26G [00:10<00:21, 43.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   9% 262M/2.88G [00:09<00:37, 69.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  27% 336M/1.26G [00:10<00:19, 48.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   9% 273M/2.88G [00:11<02:24, 18.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  48% 325M/681M [00:12<00:19, 17.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  27% 346M/1.26G [00:12<01:03, 14.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  10% 283M/2.88G [00:11<01:56, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  29% 367M/1.26G [00:12<00:38, 23.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  51% 346M/681M [00:12<00:12, 25.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  11% 304M/2.88G [00:11<01:21, 31.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  30% 377M/1.26G [00:12<00:32, 27.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  52% 357M/681M [00:12<00:11, 29.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  11% 315M/2.88G [00:11<01:09, 36.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  31% 388M/1.26G [00:12<00:26, 32.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  54% 367M/681M [00:12<00:09, 34.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  11% 325M/2.88G [00:12<00:58, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  55% 377M/681M [00:12<00:07, 41.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  32% 398M/1.26G [00:13<00:21, 39.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  12% 336M/2.88G [00:12<00:51, 49.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  57% 388M/681M [00:12<00:06, 47.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  32% 409M/1.26G [00:13<00:18, 45.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  12% 346M/2.88G [00:12<00:46, 54.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  33% 419M/1.26G [00:13<00:15, 53.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  59% 398M/681M [00:13<00:05, 53.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  12% 357M/2.88G [00:12<00:42, 59.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  34% 430M/1.26G [00:13<00:14, 57.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  60% 409M/681M [00:13<00:04, 57.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  35% 440M/1.26G [00:16<01:19, 10.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  62% 419M/681M [00:16<00:24, 10.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  65% 440M/681M [00:16<00:13, 18.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  37% 472M/1.26G [00:16<00:36, 21.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  13% 367M/2.88G [00:15<04:12, 9.93MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  38% 482M/1.26G [00:16<00:29, 26.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  68% 461M/681M [00:16<00:08, 27.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  39% 493M/1.26G [00:16<00:24, 31.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  13% 388M/2.88G [00:15<02:28, 16.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  40% 503M/1.26G [00:17<00:20, 37.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  71% 482M/681M [00:16<00:05, 37.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  14% 398M/2.88G [00:16<01:58, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  14% 409M/2.88G [00:16<01:33, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  41% 524M/1.26G [00:17<00:14, 52.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  74% 503M/681M [00:16<00:03, 47.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  15% 419M/2.88G [00:16<01:15, 32.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  43% 545M/1.26G [00:17<00:10, 67.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  15% 440M/2.88G [00:16<00:48, 50.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  16% 461M/2.88G [00:16<00:34, 70.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  77% 524M/681M [00:17<00:03, 50.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  17% 482M/2.88G [00:16<00:26, 89.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  45% 566M/1.26G [00:17<00:10, 66.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  80% 545M/681M [00:17<00:02, 65.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  46% 587M/1.26G [00:17<00:07, 85.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  17% 503M/2.88G [00:16<00:27, 87.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  83% 566M/681M [00:17<00:01, 72.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  48% 608M/1.26G [00:18<00:08, 77.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  18% 524M/2.88G [00:17<00:29, 80.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  86% 587M/681M [00:17<00:01, 73.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  88% 598M/681M [00:18<00:01, 73.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  50% 629M/1.26G [00:18<00:08, 79.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  19% 545M/2.88G [00:17<00:28, 80.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  89% 608M/681M [00:18<00:01, 57.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  51% 640M/1.26G [00:18<00:11, 55.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  19% 556M/2.88G [00:19<01:45, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  91% 619M/681M [00:20<00:03, 18.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  51% 650M/1.26G [00:20<00:29, 20.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  92% 629M/681M [00:20<00:02, 23.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  20% 566M/2.88G [00:19<01:33, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  52% 661M/1.26G [00:20<00:24, 24.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  20% 577M/2.88G [00:19<01:18, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  95% 650M/681M [00:20<00:00, 34.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  53% 671M/1.26G [00:20<00:20, 29.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  21% 598M/2.88G [00:20<00:56, 40.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  99% 671M/681M [00:20<00:00, 45.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  55% 692M/1.26G [00:21<00:14, 38.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  21% 608M/2.88G [00:20<00:51, 44.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors: 100% 681M/681M [00:20<00:00, 47.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors: 100% 681M/681M [00:20<00:00, 32.5MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  21% 619M/2.88G [00:20<00:45, 49.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  56% 713M/1.26G [00:21<00:11, 49.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  22% 629M/2.88G [00:20<00:42, 53.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  57% 724M/1.26G [00:21<00:10, 52.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  22% 640M/2.88G [00:20<00:38, 57.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  59% 744M/1.26G [00:21<00:07, 72.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  23% 661M/2.88G [00:20<00:27, 80.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  61% 765M/1.26G [00:21<00:05, 91.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  24% 682M/2.88G [00:20<00:21, 99.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  62% 786M/1.26G [00:21<00:04, 110MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  24% 703M/2.88G [00:20<00:18, 120MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  64% 807M/1.26G [00:22<00:03, 127MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  26% 734M/2.88G [00:21<00:16, 128MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  66% 828M/1.26G [00:22<00:04, 101MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  26% 755M/2.88G [00:21<00:20, 106MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  67% 849M/1.26G [00:22<00:04, 96.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  27% 776M/2.88G [00:21<00:18, 111MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  69% 870M/1.26G [00:22<00:04, 94.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  28% 797M/2.88G [00:21<00:22, 94.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  71% 902M/1.26G [00:22<00:02, 125MB/s] \u001b[A\n",
            "model.safetensors:  73% 923M/1.26G [00:23<00:02, 122MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  28% 818M/2.88G [00:22<00:27, 75.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  75% 954M/1.26G [00:23<00:02, 128MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  29% 828M/2.88G [00:22<00:26, 78.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  29% 839M/2.88G [00:22<00:27, 74.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  77% 975M/1.26G [00:23<00:02, 105MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  30% 870M/2.88G [00:22<00:19, 101MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  79% 996M/1.26G [00:23<00:02, 113MB/s]\u001b[A\n",
            "model.safetensors:  80% 1.02G/1.26G [00:23<00:01, 129MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  31% 891M/2.88G [00:22<00:18, 107MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  82% 1.04G/1.26G [00:24<00:01, 139MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  32% 912M/2.88G [00:23<00:16, 119MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  84% 1.06G/1.26G [00:24<00:01, 139MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  32% 933M/2.88G [00:25<01:26, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  85% 1.08G/1.26G [00:26<00:07, 23.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  34% 965M/2.88G [00:25<00:54, 35.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  88% 1.11G/1.26G [00:26<00:04, 35.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  34% 986M/2.88G [00:26<00:42, 44.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  90% 1.13G/1.26G [00:27<00:02, 44.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  35% 1.01G/2.88G [00:26<00:33, 55.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  91% 1.15G/1.26G [00:27<00:01, 56.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  36% 1.03G/2.88G [00:26<00:27, 68.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  93% 1.17G/1.26G [00:27<00:01, 69.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  36% 1.05G/2.88G [00:26<00:22, 82.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  95% 1.20G/1.26G [00:27<00:00, 85.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  37% 1.07G/2.88G [00:26<00:18, 98.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  96% 1.22G/1.26G [00:27<00:00, 102MB/s] \u001b[A\n",
            "model.safetensors:  98% 1.24G/1.26G [00:27<00:00, 107MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  38% 1.09G/2.88G [00:26<00:21, 83.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors: 100% 1.26G/1.26G [00:27<00:00, 119MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors: 100% 1.26G/1.26G [00:28<00:00, 45.1MB/s]\n",
            "Fetching 19 files:  21% 4/19 [00:28<01:53,  7.59s/it]\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  40% 1.14G/2.88G [00:27<00:14, 121MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  40% 1.16G/2.88G [00:27<00:13, 126MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  41% 1.18G/2.88G [00:27<00:13, 126MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  42% 1.21G/2.88G [00:27<00:14, 115MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  43% 1.23G/2.88G [00:30<01:10, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  44% 1.26G/2.88G [00:30<00:44, 36.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  45% 1.29G/2.88G [00:30<00:30, 52.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  46% 1.32G/2.88G [00:30<00:22, 70.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  47% 1.35G/2.88G [00:30<00:16, 93.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  48% 1.38G/2.88G [00:31<00:15, 94.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  49% 1.41G/2.88G [00:31<00:14, 102MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  50% 1.44G/2.88G [00:31<00:11, 129MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  51% 1.47G/2.88G [00:31<00:09, 152MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  52% 1.50G/2.88G [00:31<00:07, 178MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  53% 1.53G/2.88G [00:31<00:06, 199MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  54% 1.56G/2.88G [00:31<00:06, 190MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  55% 1.59G/2.88G [00:32<00:06, 213MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  56% 1.63G/2.88G [00:32<00:05, 229MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  58% 1.66G/2.88G [00:32<00:05, 242MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  59% 1.69G/2.88G [00:32<00:04, 251MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  60% 1.72G/2.88G [00:32<00:04, 254MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  61% 1.75G/2.88G [00:32<00:04, 257MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  62% 1.78G/2.88G [00:32<00:06, 177MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  63% 1.81G/2.88G [00:33<00:06, 163MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  64% 1.84G/2.88G [00:33<00:07, 142MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  64% 1.86G/2.88G [00:33<00:08, 117MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  66% 1.89G/2.88G [00:33<00:06, 148MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  67% 1.92G/2.88G [00:33<00:06, 155MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  68% 1.95G/2.88G [00:34<00:05, 181MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  69% 1.98G/2.88G [00:34<00:04, 200MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  70% 2.01G/2.88G [00:34<00:04, 178MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  71% 2.03G/2.88G [00:35<00:14, 59.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  71% 2.06G/2.88G [00:35<00:11, 72.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  72% 2.08G/2.88G [00:35<00:09, 85.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  73% 2.11G/2.88G [00:35<00:06, 111MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  74% 2.14G/2.88G [00:36<00:05, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  75% 2.17G/2.88G [00:36<00:04, 164MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  77% 2.20G/2.88G [00:36<00:03, 192MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  78% 2.23G/2.88G [00:36<00:03, 183MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  79% 2.26G/2.88G [00:36<00:04, 153MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  79% 2.29G/2.88G [00:41<00:36, 16.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  80% 2.31G/2.88G [00:42<00:28, 20.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  82% 2.35G/2.88G [00:42<00:16, 32.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  83% 2.38G/2.88G [00:42<00:11, 44.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  84% 2.41G/2.88G [00:42<00:07, 59.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  85% 2.44G/2.88G [00:42<00:05, 77.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  86% 2.47G/2.88G [00:42<00:04, 99.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  87% 2.52G/2.88G [00:42<00:02, 133MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  89% 2.55G/2.88G [00:43<00:02, 153MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  90% 2.58G/2.88G [00:43<00:01, 168MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  91% 2.61G/2.88G [00:43<00:01, 192MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  92% 2.64G/2.88G [00:43<00:01, 208MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  93% 2.67G/2.88G [00:43<00:00, 224MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  94% 2.71G/2.88G [00:43<00:00, 235MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  95% 2.74G/2.88G [00:43<00:00, 234MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  96% 2.77G/2.88G [00:43<00:00, 229MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  97% 2.80G/2.88G [00:44<00:00, 248MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  98% 2.83G/2.88G [00:44<00:00, 238MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors: 100% 2.88G/2.88G [00:44<00:00, 64.9MB/s]\n",
            "Fetching 19 files: 100% 19/19 [00:45<00:00,  2.40s/it]\n",
            "Loading weights from local directory\n",
            "Loading weights from local directory\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# --- FINAL RELEASE (Colab Free Tier Attempt): Paints-UNDO Setup and Launch ---\n",
        "# Adapted from working Kaggle script.\n",
        "# WARNING: HIGH LIKELIHOOD OF FAILURE due to Colab Free Tier System RAM limitations (~12.7 GB).\n",
        "# Expect potential crash during model loading after installations complete.\n",
        "\n",
        "import os\n",
        "import re\n",
        "import fileinput\n",
        "import site # To find site-packages\n",
        "import sys # To check python version for path fallback\n",
        "\n",
        "# 1. Check Resources (GPU and RAM)\n",
        "print(\"--- Step 0: Checking Resources ---\")\n",
        "!nvidia-smi\n",
        "print(\"\\nSystem RAM:\")\n",
        "!free -h\n",
        "print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
        "\n",
        "# Define working directory for Colab\n",
        "WORKING_DIR = \"/content/\"\n",
        "REPO_DIR = os.path.join(WORKING_DIR, \"Paints-UNDO\")\n",
        "\n",
        "# 2. Clone the Repository\n",
        "print(\"--- Step 1: Cloning Repository ---\")\n",
        "# Remove previous clone if it exists to start fresh\n",
        "!rm -rf {REPO_DIR}\n",
        "os.chdir(WORKING_DIR) # Ensure we are in /content before cloning\n",
        "!git clone https://github.com/lllyasviel/Paints-UNDO.git\n",
        "%cd {REPO_DIR}\n",
        "print(f\"Changed directory to: {REPO_DIR}\")\n",
        "print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
        "\n",
        "# 3. Install Dependencies (Strategy: Let peft choose transformers, use diffusers==0.29.0, upgrade Gradio, force numpy<2.0)\n",
        "print(\"--- Step 2: Installing Dependencies ---\")\n",
        "print(\"Creating temporary requirements file excluding diffusers, gradio, transformers...\")\n",
        "# Create a temporary requirements file excluding conflicting/managed packages\n",
        "!grep -v '^diffusers==' requirements.txt | grep -v '^gradio==' | grep -v '^transformers==' > temp_requirements.txt\n",
        "\n",
        "print(\"Installing base requirements (including peft, which will pull its transformers)...\")\n",
        "# Use --use-deprecated=legacy-resolver if dependency errors occur, but try without first\n",
        "!pip install --no-cache-dir -r temp_requirements.txt # Removed legacy-resolver for now\n",
        "\n",
        "print(\"\\nInstalling specific diffusers version (0.29.0)...\")\n",
        "!pip install --no-cache-dir diffusers==0.29.0\n",
        "\n",
        "print(\"\\nUpgrading Gradio and Client...\")\n",
        "!pip install --no-cache-dir --upgrade gradio gradio-client\n",
        "\n",
        "print(\"\\nForce installing NumPy < 2.0 (numpy==1.26.4) for compatibility...\")\n",
        "!pip install --no-cache-dir \"numpy<2.0\" numpy==1.26.4 --force-reinstall\n",
        "\n",
        "# Clean up temporary file\n",
        "!rm temp_requirements.txt\n",
        "print(\"--- Dependencies Installation Complete ---\")\n",
        "print(\"\\n--- Verifying Key Package Versions ---\")\n",
        "!pip show gradio transformers huggingface-hub diffusers peft numpy | grep -E '^Name:|^Version:'\n",
        "print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
        "\n",
        "\n",
        "# 4. Patch the installed transformers library for CLIP Vision model compatibility\n",
        "print(\"--- Step 3: Patching installed transformers library ---\")\n",
        "try:\n",
        "    # Find site-packages directory more reliably\n",
        "    site_packages_paths = site.getsitepackages()\n",
        "    transformers_clip_path = None\n",
        "    py_version_short = f\"python{sys.version_info.major}.{sys.version_info.minor}\" # e.g., python3.10\n",
        "\n",
        "    for path in site_packages_paths:\n",
        "         # Look for the specific file within transformers install location\n",
        "         potential_path = os.path.join(path, \"transformers/models/clip/modeling_clip.py\")\n",
        "         if os.path.exists(potential_path):\n",
        "              transformers_clip_path = potential_path\n",
        "              print(f\"Found transformers file at: {transformers_clip_path}\")\n",
        "              break\n",
        "\n",
        "    # Fallback if not found in standard site-packages (adjust python version)\n",
        "    if not transformers_clip_path:\n",
        "         site_packages_path = f'/usr/local/lib/{py_version_short}/dist-packages'\n",
        "         transformers_clip_path = os.path.join(site_packages_path, \"transformers/models/clip/modeling_clip.py\")\n",
        "         if os.path.exists(transformers_clip_path):\n",
        "             print(f\"Found transformers file at fallback path: {transformers_clip_path}\")\n",
        "         else:\n",
        "             transformers_clip_path = None # Explicitly None if not found\n",
        "\n",
        "    if transformers_clip_path and os.path.exists(transformers_clip_path):\n",
        "        patch_applied = False\n",
        "        modified_lines = []\n",
        "        target_line_found = False\n",
        "\n",
        "        # Read all lines first\n",
        "        with open(transformers_clip_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        # Find and modify the specific line, preserving indentation\n",
        "        for i, line in enumerate(lines):\n",
        "            # Define the argument string to remove more carefully\n",
        "            arg_to_remove_pattern = r',?\\s*interpolate_pos_encoding\\s*=\\s*interpolate_pos_encoding'\n",
        "            # Check if the line contains the specific call and the argument\n",
        "            # Be slightly more robust to variations in the call\n",
        "            if 'self.embeddings(' in line and 'interpolate_pos_encoding=' in line:\n",
        "                target_line_found = True\n",
        "                # Remove the argument using regex substitution\n",
        "                original_line_strip = line.strip()\n",
        "                modified_content = re.sub(arg_to_remove_pattern, '', line)\n",
        "                modified_lines.append(modified_content) # Append the modified line\n",
        "                print(f\"  Original Line {i+1}: {original_line_strip}\")\n",
        "                print(f\"  Patched Line {i+1}:  {modified_content.strip()}\")\n",
        "                patch_applied = True\n",
        "            else:\n",
        "                modified_lines.append(line) # Keep original line\n",
        "\n",
        "        if patch_applied:\n",
        "            # Write the modified content back\n",
        "            print(\"Writing patched file...\")\n",
        "            backup_file = transformers_clip_path + '.bak'\n",
        "            if os.path.exists(backup_file): # Avoid multiple backups piling up\n",
        "                 os.remove(backup_file)\n",
        "            os.rename(transformers_clip_path, backup_file) # Create backup\n",
        "            with open(transformers_clip_path, 'w') as f:\n",
        "                f.writelines(modified_lines)\n",
        "            print(\"--- Successfully patched modeling_clip.py ---\")\n",
        "        elif target_line_found:\n",
        "             print(\"--- WARNING: Target line found but patch regex might not have matched. Check manually if issues persist. ---\")\n",
        "        else:\n",
        "            print(\"--- WARNING: Target line for patching 'interpolate_pos_encoding' not found in modeling_clip.py. This might be OK if the installed transformers version doesn't use it, or patch needed elsewhere. ---\")\n",
        "    else:\n",
        "        print(f\"--- ERROR: Could not find modeling_clip.py in site-packages to patch. Searched paths: {site_packages_paths} and fallback '/usr/local/lib/{py_version_short}/dist-packages'. ---\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"--- ERROR during patching: {e} ---\")\n",
        "print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
        "\n",
        "# 5. Modify the Gradio launch command to enable sharing\n",
        "print(\"--- Step 4: Ensuring share=True in Gradio App ---\")\n",
        "gradio_app_path = 'gradio_app.py'\n",
        "try:\n",
        "    with open(gradio_app_path, 'r') as f:\n",
        "        content = f.read()\n",
        "    # Use regex for a more robust replacement/addition\n",
        "    if '.launch(' in content:\n",
        "        if 'share=True' in content:\n",
        "            print(\"share=True already present.\")\n",
        "        else:\n",
        "            # Try to add share=True inside existing parentheses\n",
        "            new_content = re.sub(r\"(\\.launch\\([^)]*)(\\))\", r\"\\1, share=True\\2\", content, count=1)\n",
        "            if new_content != content:\n",
        "                 with open(gradio_app_path, 'w') as f:\n",
        "                      f.write(new_content)\n",
        "                 print(\"Added share=True to launch() call.\")\n",
        "            else:\n",
        "                 print(\"Could not automatically add share=True (pattern mismatch?).\")\n",
        "    else:\n",
        "         print(\"WARNING: '.launch(' call not found in gradio_app.py\")\n",
        "\n",
        "    # Verify the change (optional)\n",
        "    print(\"--- Checking modification (last few lines of gradio_app.py) ---\")\n",
        "    !tail -n 5 gradio_app.py\n",
        "    print(\"\\n\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: {gradio_app_path} not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error modifying {gradio_app_path}: {e}\")\n",
        "print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
        "\n",
        "\n",
        "# 6. Run the Gradio Application\n",
        "print(\"--- Step 5: Launching Gradio App on Colab Free Tier ---\")\n",
        "print(\"Watch System RAM usage closely in 'Runtime -> View resources'.\")\n",
        "print(\"EXPECTED TO FAIL due to RAM limits during model loading.\")\n",
        "!python gradio_app.py --server_name 0.0.0.0 --enable-queue # Using 0.0.0.0 for consistency, Colab/Gradio will handle tunneling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Paints-UNDO"
      ],
      "metadata": {
        "id": "VBjBzMuLECtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python gradio_app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVUtpy5RD_9H",
        "outputId": "5d563950-dae0-42b3-fd63-c200bc99e039"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "2025-04-06 12:37:05.951157: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743943026.230163    1972 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743943026.295961    1972 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "The config attributes {'shift_factor': None, 'use_post_quant_conv': True, 'use_quant_conv': True} were passed to AutoencoderKL, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
            "Fetching 19 files: 100% 19/19 [00:00<00:00, 133711.03it/s]\n",
            "Loading weights from local directory\n",
            "Loading weights from local directory\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}